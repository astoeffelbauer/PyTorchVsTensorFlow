{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch vs TensorFlow in Code\n",
    "\n",
    "Gibhub code to Blogpost on Medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiments</th>\n",
       "      <th>tweets</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Sex and the city is the best</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>@mileycyrus i'll come if you can get me tickets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>trying to change my bg pic but twiter is not l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>go to my father's house or not?!that is the qu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>gonna sleep on this day. gotta get new contact...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>@Lelebee idk if mine does</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>@flourishes Sounds like a good way to wake up!...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>Giving my father a foot massage. Keeping him c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>I have the best friends in the whole world. I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>I'm watching Hank n Jim's replay at http://sti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiments                                             tweets\n",
       "0           1                      Sex and the city is the best \n",
       "1           1   @mileycyrus i'll come if you can get me tickets \n",
       "2           0  trying to change my bg pic but twiter is not l...\n",
       "3           0  go to my father's house or not?!that is the qu...\n",
       "4           0  gonna sleep on this day. gotta get new contact...\n",
       "5           0                         @Lelebee idk if mine does \n",
       "6           1  @flourishes Sounds like a good way to wake up!...\n",
       "7           0  Giving my father a foot massage. Keeping him c...\n",
       "8           1  I have the best friends in the whole world. I ...\n",
       "9           0  I'm watching Hank n Jim's replay at http://sti..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data_path = \"./data/tweets_short.csv\"\n",
    "\n",
    "data = pd.read_csv(data_path, encoding='utf-8')\n",
    "data[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data from csv file\n",
    "\n",
    "data_path = './data/tweets.csv'\n",
    "\n",
    "data = pd.read_csv(data_path, usecols=[0,5], encoding='utf-8', names=['sentiments', 'tweets'])\n",
    "data = data.sample(frac=.10)  # shuffle the tweets\n",
    "data.sentiments = [0 if x==0 else 1 for x in data.sentiments]  # \n",
    "\n",
    "new_data_path = \"./data/tweets_short.csv\"\n",
    "data.to_csv(new_data_path, header=True, index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "# instantiate and fit tokenizer\n",
    "tokenizer = Tokenizer(num_words=20000, oov_token='<00v>')\n",
    "tokenizer.fit_on_texts(data.tweets)\n",
    "\n",
    "# transform tweets into sequences of integers\n",
    "sequences = tokenizer.texts_to_sequences(data.tweets)\n",
    "\n",
    "# pad sequences so that they have uniform lenth\n",
    "padded = tf.keras.preprocessing.sequence.pad_sequences(sequences, maxlen=42)\n",
    "assert(padded.shape==(40000,42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq = padded\n",
    "labels = np.array(data.sentiments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow 2.0\n",
    "\n",
    "## 1. Subclassing API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Subclass_Model(tf.keras.Model):\n",
    "    \n",
    "    def __init__(self, embedding_dim=25):\n",
    "        \n",
    "        super(Subclass_Model, self).__init__()\n",
    "        self.embedding_layer = tf.keras.layers.Embedding(input_dim=20000,\n",
    "                                                         output_dim=50,\n",
    "                                                         input_length=42)\n",
    "        \n",
    "        self.pool1D_layer = tf.keras.layers.GlobalAveragePooling1D()\n",
    "        self.fc_layer =  tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        \n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.pool1D_layer(x)\n",
    "        return self.fc_layer(x)\n",
    "    \n",
    "model = Subclass_Model()\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 42)]              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 42, 50)            1000000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_3 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,000,051\n",
      "Trainable params: 1,000,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = tf.keras.layers.Input(shape=(42,))\n",
    "x = tf.keras.layers.Embedding(input_dim=20000,\n",
    "                              output_dim=50,\n",
    "                              input_length=42)(inputs)\n",
    "\n",
    "x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "outputs = tf.keras.layers.Dense(units=1, activation='sigmoid')(x)\n",
    "\n",
    "model = tf.keras.models.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Sequential API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 42, 50)            1000000   \n",
      "_________________________________________________________________\n",
      "global_average_pooling1d_5 ( (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 1,000,051\n",
      "Trainable params: 1,000,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.Embedding(input_dim=20000,\n",
    "                                    output_dim=50,\n",
    "                                    input_length=42))\n",
    "\n",
    "model.add(tf.keras.layers.GlobalAveragePooling1D())\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 32000 samples, validate on 8000 samples\n",
      "32000/32000 - 22s - loss: 0.6332 - accuracy: 0.6731 - val_loss: 0.5635 - val_accuracy: 0.7383\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20eeb8fd1c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "model.fit(x=seq,\n",
    "          y=labels,\n",
    "          batch_size=32,\n",
    "          epochs=1,\n",
    "          verbose=2,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does not work here :(\n",
    "# tf.keras.utils.plot_model(model, to_file='model.png', show_shapes=False, show_layer_names=True, rankdir='TB', expand_nested=False, dpi=96)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tweets, sentiments):\n",
    "        self.tweets = tweets\n",
    "        self.sentiments = sentiments\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sample = {\"tweets\":torch.LongTensor(self.tweets[index,:]),\n",
    "                  \"sentiments\":self.sentiments[index]}\n",
    "        \n",
    "        return sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.tweets.shape[0]\n",
    "    \n",
    "    \n",
    "tweets_dataset = MyDataset(seq, labels.astype(float))\n",
    "dataloader = DataLoader(tweets_dataset,\n",
    "                        batch_size=32,\n",
    "                        shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Subclassing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.embedding_layer = nn.Embedding(num_embeddings=20000,\n",
    "                                            embedding_dim=50)\n",
    "        self.pooling_layer = nn.AvgPool1d(kernel_size=50)\n",
    "        self.fc_layer = nn.Linear(in_features=42, out_features=1)\n",
    "        \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        \n",
    "        x = self.embedding_layer(inputs)\n",
    "        x = self.pooling_layer(x).view(32, 42)\n",
    "        \n",
    "        return torch.sigmoid(self.fc_layer(x))\n",
    "    \n",
    "model = Model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(\n",
    "    nn.Embedding(num_embeddings=20000, embedding_dim=50),\n",
    "    nn.AvgPool1d(kernel_size=50),\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=42, out_features=1),\n",
    "    nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\andreas stöffelbauer\\appdata\\local\\programs\\python\\python37\\lib\\site-packages\\torch\\nn\\modules\\loss.py:498: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])) is deprecated. Please ensure they have the same size.\n",
      "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# PyTorch training loop\n",
    "\n",
    "#define the loss fn and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# empty list to track batch losses\n",
    "batch_losses = []\n",
    "\n",
    "#train the neural network for 5 epochs\n",
    "for epoch in range(1):\n",
    "\n",
    "    #reset iterator\n",
    "    dataiter = iter(dataloader)\n",
    "    \n",
    "    #iterate over dataset\n",
    "    for batch in dataiter:\n",
    "                \n",
    "        #reset gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #forward propagation through the network\n",
    "        out = model(batch[\"tweets\"])\n",
    "        \n",
    "        #print(out.shape, batch[\"sentiments\"].shape)\n",
    "        #calculate the loss\n",
    "        loss = criterion(out, batch[\"sentiments\"])\n",
    "        \n",
    "        #track batch loss\n",
    "        batch_losses.append(loss.item())\n",
    "        \n",
    "        #backpropagation\n",
    "        loss.backward()\n",
    "        \n",
    "        #update the parameters\n",
    "        optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
